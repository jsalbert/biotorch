{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optical-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from biotorch.initialization.functions import convert_module, count_layers\n",
    "from biotorch.layers import Conv2d, Linear\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "colored-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, batch_size):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # Desactivate the autograd engine in test\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            #data = data.view(batch_size, -1)\n",
    "            inputs, targets = data.to(device), target.to(device)\n",
    "            predictions = model(inputs)\n",
    "            predictions = torch.squeeze(predictions)\n",
    "            test_loss += F.nll_loss(predictions, targets, size_average=False).item()\n",
    "            pred = predictions.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(targets.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8155ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "psychological-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# set up datasets\n",
    "print('==> Preparing data..')\n",
    "train_loader = DataLoader(datasets.CIFAR10('./data', train=True, download=True,\n",
    "                                                 transform=transforms.Compose([\n",
    "                                                     transforms.Resize(224),\n",
    "                                                     transforms.ToTensor(),\n",
    "                                                     transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                 ])),\n",
    "                                  batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(datasets.CIFAR10('./data', train=False, download=True,\n",
    "                                                transform=transforms.Compose([\n",
    "                                                    transforms.Resize(224),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                ])),\n",
    "                                 batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supported-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the network\n",
    "from torchvision.models import resnet\n",
    "model_fa = resnet.resnet18(pretrained=True)\n",
    "model_fa.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63c1392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the 20 <class 'torch.nn.modules.conv.Conv2d'> layers were converted successfully\n",
      "All the 1 <class 'torch.nn.modules.linear.Linear'> layers were converted successfully\n"
     ]
    }
   ],
   "source": [
    "convert_module(model_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c43957a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'biotorch.layers.conv.Conv2d'>\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(type(model_fa.conv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cac0f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.models.resnet.ResNet'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torchvision.models.resnet.BasicBlock'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torchvision.models.resnet.BasicBlock'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torchvision.models.resnet.BasicBlock'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torchvision.models.resnet.BasicBlock'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torchvision.models.resnet.BasicBlock'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torchvision.models.resnet.BasicBlock'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torchvision.models.resnet.BasicBlock'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torchvision.models.resnet.BasicBlock'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "<class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>\n",
      "<class 'biotorch.layers.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_fa.modules()):\n",
    "    print(type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "926e851c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_impl',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_make_layer',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_norm_layer',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'avgpool',\n",
       " 'base_width',\n",
       " 'bfloat16',\n",
       " 'bn1',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'conv1',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'dilation',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fc',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'groups',\n",
       " 'half',\n",
       " 'inplanes',\n",
       " 'layer1',\n",
       " 'layer2',\n",
       " 'layer3',\n",
       " 'layer4',\n",
       " 'load_state_dict',\n",
       " 'maxpool',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_parameter',\n",
       " 'relu',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a79b129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,\n",
      "            1.7083e-02, -1.2694e-02],\n",
      "          [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,\n",
      "           -1.2907e-01,  3.7424e-03],\n",
      "          [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,\n",
      "            2.5632e-01,  6.3573e-02],\n",
      "          ...,\n",
      "          [-2.7535e-02,  1.6045e-02,  7.2595e-02,  ..., -3.3285e-01,\n",
      "           -4.2058e-01, -2.5781e-01],\n",
      "          [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  ...,  4.1384e-01,\n",
      "            3.9359e-01,  1.6606e-01],\n",
      "          [-1.3736e-02, -3.6746e-03, -2.4084e-02,  ..., -1.5070e-01,\n",
      "           -8.2230e-02, -5.7828e-03]],\n",
      "\n",
      "         [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  ...,  3.2521e-02,\n",
      "            6.6221e-04, -2.5743e-02],\n",
      "          [ 4.5687e-02,  3.3603e-02, -1.0453e-01,  ..., -3.1253e-01,\n",
      "           -1.6051e-01, -1.2826e-03],\n",
      "          [-8.3730e-04,  9.8420e-02,  4.0210e-01,  ...,  7.0789e-01,\n",
      "            3.6887e-01,  1.2455e-01],\n",
      "          ...,\n",
      "          [-5.5926e-02, -5.2239e-03,  2.7081e-02,  ..., -4.6178e-01,\n",
      "           -5.7080e-01, -3.6552e-01],\n",
      "          [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  ...,  5.4636e-01,\n",
      "            4.8276e-01,  1.9867e-01],\n",
      "          [ 5.3051e-03,  6.6938e-03, -1.7254e-02,  ..., -1.4822e-01,\n",
      "           -7.7248e-02,  7.2183e-04]],\n",
      "\n",
      "         [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  ...,  8.9177e-02,\n",
      "            3.3655e-02, -2.0102e-02],\n",
      "          [ 1.5398e-02, -1.8648e-02, -1.2591e-01,  ..., -2.5342e-01,\n",
      "           -1.2980e-01, -2.7975e-02],\n",
      "          [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  ...,  3.4872e-01,\n",
      "            1.0433e-01,  1.8413e-02],\n",
      "          ...,\n",
      "          [-2.8356e-02,  1.8404e-02,  9.8647e-02,  ..., -1.1740e-01,\n",
      "           -2.5760e-01, -1.5451e-01],\n",
      "          [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  ...,  2.4141e-01,\n",
      "            2.4345e-01,  1.1796e-01],\n",
      "          [ 7.4684e-04,  7.7677e-04, -1.0050e-02,  ..., -1.4865e-01,\n",
      "           -1.1754e-01, -3.8350e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4154e-03, -4.0645e-03,  3.1589e-03,  ..., -3.7026e-02,\n",
      "           -2.5158e-02, -4.7945e-02],\n",
      "          [ 5.1310e-02,  5.3402e-02,  8.0436e-02,  ...,  1.4480e-01,\n",
      "            1.4287e-01,  1.2312e-01],\n",
      "          [-7.3337e-03,  2.1755e-03,  3.7580e-02,  ...,  6.1517e-02,\n",
      "            8.0324e-02,  1.1715e-01],\n",
      "          ...,\n",
      "          [-2.6754e-02, -1.2297e-01, -1.3653e-01,  ..., -1.4068e-01,\n",
      "           -1.1155e-01, -4.9556e-02],\n",
      "          [ 2.3524e-02, -1.7288e-02, -1.1122e-02,  ..., -1.8826e-02,\n",
      "           -2.3320e-02, -2.9474e-02],\n",
      "          [ 2.8689e-02,  2.1659e-02,  4.7888e-02,  ...,  2.5498e-02,\n",
      "            3.5346e-02,  1.1280e-02]],\n",
      "\n",
      "         [[ 4.6919e-04,  1.2153e-02,  4.2035e-02,  ...,  4.6403e-02,\n",
      "            4.0423e-02, -1.4439e-02],\n",
      "          [ 4.3463e-02,  6.8779e-02,  1.3268e-01,  ...,  2.8606e-01,\n",
      "            2.6905e-01,  2.0935e-01],\n",
      "          [-5.7621e-02, -2.2642e-02,  3.0547e-02,  ...,  1.3763e-01,\n",
      "            1.6538e-01,  1.7946e-01],\n",
      "          ...,\n",
      "          [-1.0816e-01, -2.5227e-01, -2.9742e-01,  ..., -2.8503e-01,\n",
      "           -2.1493e-01, -1.0320e-01],\n",
      "          [ 4.0709e-02, -3.2771e-02, -6.3450e-02,  ..., -9.2360e-02,\n",
      "           -6.9876e-02, -4.9841e-02],\n",
      "          [ 8.2942e-02,  8.7580e-02,  1.0111e-01,  ...,  5.2714e-02,\n",
      "            6.0968e-02,  4.1198e-02]],\n",
      "\n",
      "         [[-1.6391e-02, -1.3870e-02,  5.2810e-03,  ...,  4.3698e-02,\n",
      "            2.2707e-02, -4.5983e-02],\n",
      "          [ 3.3202e-02,  4.2014e-02,  9.3500e-02,  ...,  2.6162e-01,\n",
      "            2.2970e-01,  1.6694e-01],\n",
      "          [-4.5987e-02, -1.6365e-02,  2.6811e-02,  ...,  1.4951e-01,\n",
      "            1.3216e-01,  1.3579e-01],\n",
      "          ...,\n",
      "          [-7.2129e-02, -1.8902e-01, -2.3389e-01,  ..., -1.9038e-01,\n",
      "           -1.5609e-01, -7.5974e-02],\n",
      "          [ 5.1161e-02, -2.5815e-02, -6.9357e-02,  ..., -5.8999e-02,\n",
      "           -6.1550e-02, -4.4555e-02],\n",
      "          [ 1.1174e-01,  7.8979e-02,  6.5849e-02,  ...,  3.1617e-02,\n",
      "            2.5221e-02,  7.4257e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
      "           -1.0905e-07, -8.3421e-08],\n",
      "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
      "           -4.3836e-08, -3.0538e-09],\n",
      "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
      "           -1.0951e-09,  4.2442e-08],\n",
      "          ...,\n",
      "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
      "           -4.7666e-08, -1.3265e-08],\n",
      "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
      "            1.0628e-07,  9.3316e-08],\n",
      "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
      "            1.7710e-07,  1.7166e-07]],\n",
      "\n",
      "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
      "           -1.3309e-07, -1.0820e-07],\n",
      "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
      "           -6.7022e-08, -2.2574e-08],\n",
      "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
      "           -7.9591e-09,  3.9750e-08],\n",
      "          ...,\n",
      "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
      "           -5.9930e-08, -1.8247e-08],\n",
      "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
      "            4.1781e-08,  4.5901e-08],\n",
      "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
      "            8.7550e-08,  9.8837e-08]],\n",
      "\n",
      "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
      "           -2.6217e-08, -1.5649e-08],\n",
      "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
      "            7.1450e-08,  9.7615e-08],\n",
      "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
      "            1.3487e-07,  1.6449e-07],\n",
      "          ...,\n",
      "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
      "            6.8382e-08,  1.1367e-07],\n",
      "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
      "            1.1723e-07,  1.4394e-07],\n",
      "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
      "            1.3333e-07,  1.5844e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.1896e-02, -3.0206e-02,  1.9225e-02,  ...,  4.3665e-02,\n",
      "           -2.2114e-02, -4.2214e-02],\n",
      "          [-3.8061e-02,  6.0774e-03,  4.5797e-02,  ...,  9.6029e-02,\n",
      "            5.9254e-02,  2.9958e-02],\n",
      "          [-2.9672e-02,  2.7766e-03,  2.0457e-02,  ...,  5.9828e-02,\n",
      "            4.1422e-02,  2.3134e-02],\n",
      "          ...,\n",
      "          [ 1.1916e-02,  4.5701e-02,  4.4892e-02,  ...,  4.7419e-02,\n",
      "            2.2274e-02, -5.4993e-03],\n",
      "          [-3.2468e-02, -1.2210e-02,  2.2023e-02,  ...,  5.8061e-02,\n",
      "           -7.5033e-03, -5.9736e-02],\n",
      "          [-4.3314e-02, -2.8162e-02, -5.9126e-03,  ...,  8.8460e-02,\n",
      "            8.4406e-03, -5.0019e-02]],\n",
      "\n",
      "         [[-6.1292e-02, -1.4004e-02,  1.7229e-02,  ...,  1.8349e-02,\n",
      "           -3.2708e-02, -4.1060e-02],\n",
      "          [-3.1506e-02,  2.4460e-02,  4.5516e-02,  ...,  6.6806e-02,\n",
      "            4.6687e-02,  3.3248e-02],\n",
      "          [-3.2216e-02,  2.0718e-02,  2.3343e-02,  ...,  3.5265e-02,\n",
      "            3.6478e-02,  3.1291e-02],\n",
      "          ...,\n",
      "          [ 1.7739e-02,  6.1040e-02,  4.8247e-02,  ...,  3.7785e-02,\n",
      "            2.8894e-02,  1.3984e-02],\n",
      "          [-1.0890e-02,  2.2079e-02,  4.2737e-02,  ...,  6.0247e-02,\n",
      "            1.6197e-02, -1.2493e-02],\n",
      "          [-2.2284e-02,  1.3220e-02,  3.0897e-02,  ...,  1.0403e-01,\n",
      "            4.0119e-02, -5.3310e-03]],\n",
      "\n",
      "         [[-8.5322e-02, -4.2603e-02,  6.8145e-03,  ...,  3.0751e-02,\n",
      "           -3.4818e-02, -4.9945e-02],\n",
      "          [-2.9215e-02,  1.8165e-02,  5.1092e-02,  ...,  9.0200e-02,\n",
      "            5.3438e-02,  4.0169e-02],\n",
      "          [-3.9932e-02, -1.1100e-03,  9.6176e-03,  ...,  2.4114e-02,\n",
      "            2.6298e-02,  2.5489e-02],\n",
      "          ...,\n",
      "          [-3.1890e-03,  3.0454e-02,  1.6316e-02,  ...,  5.5054e-03,\n",
      "           -6.2689e-03, -8.4638e-03],\n",
      "          [-2.2995e-02, -2.8211e-03,  2.3203e-02,  ...,  3.5888e-02,\n",
      "           -1.4296e-02, -3.2419e-02],\n",
      "          [-9.8894e-03,  7.0542e-03,  1.0659e-02,  ...,  7.0495e-02,\n",
      "            1.2996e-02, -8.3417e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.8699e-03,  1.9911e-02,  3.4208e-02,  ...,  2.8694e-02,\n",
      "            1.2820e-02,  1.8142e-02],\n",
      "          [ 8.7942e-03, -3.2875e-02, -3.5713e-02,  ...,  7.2533e-02,\n",
      "            4.5889e-02,  5.2383e-02],\n",
      "          [-3.6122e-02, -1.1878e-01, -1.3767e-01,  ...,  3.3811e-02,\n",
      "            3.7806e-02,  2.6944e-02],\n",
      "          ...,\n",
      "          [ 1.7322e-02,  3.9589e-03, -8.2269e-03,  ...,  2.7543e-03,\n",
      "            1.8313e-02,  1.6057e-02],\n",
      "          [-9.5007e-04,  1.6428e-02,  1.7156e-02,  ...,  3.3672e-03,\n",
      "            2.2857e-02,  6.5783e-04],\n",
      "          [ 6.1727e-03,  2.7145e-02,  1.4340e-02,  ...,  7.5867e-03,\n",
      "            1.8770e-02,  1.5624e-02]],\n",
      "\n",
      "         [[-1.3423e-02, -5.0696e-04,  8.0959e-03,  ..., -6.0963e-03,\n",
      "            9.2341e-03,  1.5751e-02],\n",
      "          [-1.8343e-02, -6.7982e-02, -7.0685e-02,  ...,  2.9855e-02,\n",
      "            2.6264e-02,  2.3773e-02],\n",
      "          [-5.4359e-02, -1.4663e-01, -1.6211e-01,  ...,  1.1781e-02,\n",
      "            3.2477e-02,  1.1980e-02],\n",
      "          ...,\n",
      "          [ 8.3686e-04, -1.7564e-02, -1.9535e-02,  ..., -4.1382e-03,\n",
      "            2.4658e-02,  1.2893e-02],\n",
      "          [-6.3183e-04,  1.1788e-02,  2.4810e-02,  ...,  6.1105e-03,\n",
      "            3.9210e-02,  9.6696e-03],\n",
      "          [-7.1831e-03,  6.6918e-03,  5.2723e-03,  ..., -7.6077e-03,\n",
      "            2.7253e-02,  1.7735e-02]],\n",
      "\n",
      "         [[-2.3753e-04, -4.9343e-03,  2.2991e-03,  ..., -4.7958e-02,\n",
      "           -2.6154e-02, -2.3525e-02],\n",
      "          [-3.3053e-04, -5.1502e-02, -5.9977e-02,  ..., -1.7369e-02,\n",
      "           -2.3337e-02, -3.7312e-02],\n",
      "          [-2.2674e-02, -9.9412e-02, -1.1176e-01,  ..., -1.1725e-02,\n",
      "           -8.3744e-03, -4.0615e-02],\n",
      "          ...,\n",
      "          [ 1.1437e-02, -8.0313e-03, -1.4955e-03,  ..., -3.4133e-02,\n",
      "           -8.7267e-03, -2.3526e-02],\n",
      "          [ 2.9522e-03,  6.7770e-04,  1.9933e-02,  ..., -2.2002e-02,\n",
      "            1.4814e-02, -1.4487e-02],\n",
      "          [-1.9085e-02, -2.9430e-02, -2.3284e-02,  ..., -4.8587e-02,\n",
      "           -1.3049e-02, -2.4368e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6296e-02,  7.1996e-03,  1.9100e-02,  ...,  1.9602e-02,\n",
      "            1.4870e-02, -1.7298e-02],\n",
      "          [-1.1061e-02,  8.5665e-02,  1.2667e-01,  ...,  1.3744e-02,\n",
      "           -5.5036e-05, -3.0162e-02],\n",
      "          [ 1.1322e-01,  1.8634e-01,  5.0658e-02,  ..., -1.7333e-01,\n",
      "           -7.2041e-02, -6.2474e-02],\n",
      "          ...,\n",
      "          [-5.3062e-02, -2.5781e-01, -2.6747e-01,  ...,  2.6781e-01,\n",
      "            1.4344e-01,  5.5145e-02],\n",
      "          [-2.1009e-02, -2.9969e-02,  1.0245e-01,  ...,  2.0843e-01,\n",
      "           -4.1518e-03, -3.8118e-02],\n",
      "          [-2.2155e-02,  1.2380e-02,  8.4302e-02,  ..., -4.4992e-02,\n",
      "           -1.4687e-01, -9.0890e-02]],\n",
      "\n",
      "         [[-5.3969e-03,  3.2799e-02,  1.5486e-02,  ..., -7.7451e-03,\n",
      "            3.0229e-03,  1.1216e-03],\n",
      "          [ 6.1723e-02,  1.4899e-01,  1.4645e-01,  ..., -2.8897e-02,\n",
      "           -2.0227e-02, -9.1878e-03],\n",
      "          [ 1.6146e-01,  2.0886e-01, -2.5589e-02,  ..., -2.7278e-01,\n",
      "           -1.0735e-01, -6.2971e-02],\n",
      "          ...,\n",
      "          [-1.3723e-01, -4.0863e-01, -3.8551e-01,  ...,  4.0846e-01,\n",
      "            2.6202e-01,  1.3491e-01],\n",
      "          [-5.9388e-02, -6.1187e-02,  1.4197e-01,  ...,  3.5780e-01,\n",
      "            9.0893e-02, -1.7392e-03],\n",
      "          [ 7.8613e-03,  5.8403e-02,  1.5339e-01,  ...,  4.7045e-02,\n",
      "           -1.0095e-01, -9.7920e-02]],\n",
      "\n",
      "         [[-5.6799e-03,  1.3425e-02, -2.6461e-02,  ...,  4.4881e-03,\n",
      "            2.0666e-03,  1.3902e-02],\n",
      "          [ 6.5943e-03,  4.5181e-02,  6.0260e-02,  ...,  1.4368e-02,\n",
      "           -5.0725e-03,  4.0505e-03],\n",
      "          [ 5.5257e-02,  1.2397e-01,  4.3193e-02,  ..., -1.4486e-01,\n",
      "           -7.4489e-02, -5.7533e-02],\n",
      "          ...,\n",
      "          [-3.1513e-02, -1.6334e-01, -1.5795e-01,  ...,  2.2904e-01,\n",
      "            1.2017e-01,  7.1998e-02],\n",
      "          [-1.0456e-02, -1.1248e-03,  8.4582e-02,  ...,  1.5748e-01,\n",
      "            2.2142e-02, -1.0083e-02],\n",
      "          [-4.8639e-03, -5.0065e-03,  3.6341e-02,  ..., -2.4361e-02,\n",
      "           -7.1195e-02, -6.6788e-02]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w = model_fa.conv1.weight\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065d3ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaced:  model_fa conv1\n",
      "replaced:  model_fa fc\n",
      "replaced:  0 conv1\n",
      "replaced:  0 conv2\n",
      "replaced:  1 conv1\n",
      "replaced:  1 conv2\n",
      "replaced:  0 conv1\n",
      "replaced:  0 conv2\n",
      "replaced:  downsample 0\n",
      "replaced:  1 conv1\n",
      "replaced:  1 conv2\n",
      "replaced:  0 conv1\n",
      "replaced:  0 conv2\n",
      "replaced:  downsample 0\n",
      "replaced:  1 conv1\n",
      "replaced:  1 conv2\n",
      "replaced:  0 conv1\n",
      "replaced:  0 conv2\n",
      "replaced:  downsample 0\n",
      "replaced:  1 conv1\n",
      "replaced:  1 conv2\n"
     ]
    }
   ],
   "source": [
    "replace_layers(model_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda1eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,\n",
      "            1.7083e-02, -1.2694e-02],\n",
      "          [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,\n",
      "           -1.2907e-01,  3.7424e-03],\n",
      "          [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,\n",
      "            2.5632e-01,  6.3573e-02],\n",
      "          ...,\n",
      "          [-2.7535e-02,  1.6045e-02,  7.2595e-02,  ..., -3.3285e-01,\n",
      "           -4.2058e-01, -2.5781e-01],\n",
      "          [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  ...,  4.1384e-01,\n",
      "            3.9359e-01,  1.6606e-01],\n",
      "          [-1.3736e-02, -3.6746e-03, -2.4084e-02,  ..., -1.5070e-01,\n",
      "           -8.2230e-02, -5.7828e-03]],\n",
      "\n",
      "         [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  ...,  3.2521e-02,\n",
      "            6.6221e-04, -2.5743e-02],\n",
      "          [ 4.5687e-02,  3.3603e-02, -1.0453e-01,  ..., -3.1253e-01,\n",
      "           -1.6051e-01, -1.2826e-03],\n",
      "          [-8.3730e-04,  9.8420e-02,  4.0210e-01,  ...,  7.0789e-01,\n",
      "            3.6887e-01,  1.2455e-01],\n",
      "          ...,\n",
      "          [-5.5926e-02, -5.2239e-03,  2.7081e-02,  ..., -4.6178e-01,\n",
      "           -5.7080e-01, -3.6552e-01],\n",
      "          [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  ...,  5.4636e-01,\n",
      "            4.8276e-01,  1.9867e-01],\n",
      "          [ 5.3051e-03,  6.6938e-03, -1.7254e-02,  ..., -1.4822e-01,\n",
      "           -7.7248e-02,  7.2183e-04]],\n",
      "\n",
      "         [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  ...,  8.9177e-02,\n",
      "            3.3655e-02, -2.0102e-02],\n",
      "          [ 1.5398e-02, -1.8648e-02, -1.2591e-01,  ..., -2.5342e-01,\n",
      "           -1.2980e-01, -2.7975e-02],\n",
      "          [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  ...,  3.4872e-01,\n",
      "            1.0433e-01,  1.8413e-02],\n",
      "          ...,\n",
      "          [-2.8356e-02,  1.8404e-02,  9.8647e-02,  ..., -1.1740e-01,\n",
      "           -2.5760e-01, -1.5451e-01],\n",
      "          [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  ...,  2.4141e-01,\n",
      "            2.4345e-01,  1.1796e-01],\n",
      "          [ 7.4684e-04,  7.7677e-04, -1.0050e-02,  ..., -1.4865e-01,\n",
      "           -1.1754e-01, -3.8350e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4154e-03, -4.0645e-03,  3.1589e-03,  ..., -3.7026e-02,\n",
      "           -2.5158e-02, -4.7945e-02],\n",
      "          [ 5.1310e-02,  5.3402e-02,  8.0436e-02,  ...,  1.4480e-01,\n",
      "            1.4287e-01,  1.2312e-01],\n",
      "          [-7.3337e-03,  2.1755e-03,  3.7580e-02,  ...,  6.1517e-02,\n",
      "            8.0324e-02,  1.1715e-01],\n",
      "          ...,\n",
      "          [-2.6754e-02, -1.2297e-01, -1.3653e-01,  ..., -1.4068e-01,\n",
      "           -1.1155e-01, -4.9556e-02],\n",
      "          [ 2.3524e-02, -1.7288e-02, -1.1122e-02,  ..., -1.8826e-02,\n",
      "           -2.3320e-02, -2.9474e-02],\n",
      "          [ 2.8689e-02,  2.1659e-02,  4.7888e-02,  ...,  2.5498e-02,\n",
      "            3.5346e-02,  1.1280e-02]],\n",
      "\n",
      "         [[ 4.6919e-04,  1.2153e-02,  4.2035e-02,  ...,  4.6403e-02,\n",
      "            4.0423e-02, -1.4439e-02],\n",
      "          [ 4.3463e-02,  6.8779e-02,  1.3268e-01,  ...,  2.8606e-01,\n",
      "            2.6905e-01,  2.0935e-01],\n",
      "          [-5.7621e-02, -2.2642e-02,  3.0547e-02,  ...,  1.3763e-01,\n",
      "            1.6538e-01,  1.7946e-01],\n",
      "          ...,\n",
      "          [-1.0816e-01, -2.5227e-01, -2.9742e-01,  ..., -2.8503e-01,\n",
      "           -2.1493e-01, -1.0320e-01],\n",
      "          [ 4.0709e-02, -3.2771e-02, -6.3450e-02,  ..., -9.2360e-02,\n",
      "           -6.9876e-02, -4.9841e-02],\n",
      "          [ 8.2942e-02,  8.7580e-02,  1.0111e-01,  ...,  5.2714e-02,\n",
      "            6.0968e-02,  4.1198e-02]],\n",
      "\n",
      "         [[-1.6391e-02, -1.3870e-02,  5.2810e-03,  ...,  4.3698e-02,\n",
      "            2.2707e-02, -4.5983e-02],\n",
      "          [ 3.3202e-02,  4.2014e-02,  9.3500e-02,  ...,  2.6162e-01,\n",
      "            2.2970e-01,  1.6694e-01],\n",
      "          [-4.5987e-02, -1.6365e-02,  2.6811e-02,  ...,  1.4951e-01,\n",
      "            1.3216e-01,  1.3579e-01],\n",
      "          ...,\n",
      "          [-7.2129e-02, -1.8902e-01, -2.3389e-01,  ..., -1.9038e-01,\n",
      "           -1.5609e-01, -7.5974e-02],\n",
      "          [ 5.1161e-02, -2.5815e-02, -6.9357e-02,  ..., -5.8999e-02,\n",
      "           -6.1550e-02, -4.4555e-02],\n",
      "          [ 1.1174e-01,  7.8979e-02,  6.5849e-02,  ...,  3.1617e-02,\n",
      "            2.5221e-02,  7.4257e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
      "           -1.0905e-07, -8.3421e-08],\n",
      "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
      "           -4.3836e-08, -3.0538e-09],\n",
      "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
      "           -1.0951e-09,  4.2442e-08],\n",
      "          ...,\n",
      "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
      "           -4.7666e-08, -1.3265e-08],\n",
      "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
      "            1.0628e-07,  9.3316e-08],\n",
      "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
      "            1.7710e-07,  1.7166e-07]],\n",
      "\n",
      "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
      "           -1.3309e-07, -1.0820e-07],\n",
      "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
      "           -6.7022e-08, -2.2574e-08],\n",
      "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
      "           -7.9591e-09,  3.9750e-08],\n",
      "          ...,\n",
      "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
      "           -5.9930e-08, -1.8247e-08],\n",
      "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
      "            4.1781e-08,  4.5901e-08],\n",
      "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
      "            8.7550e-08,  9.8837e-08]],\n",
      "\n",
      "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
      "           -2.6217e-08, -1.5649e-08],\n",
      "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
      "            7.1450e-08,  9.7615e-08],\n",
      "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
      "            1.3487e-07,  1.6449e-07],\n",
      "          ...,\n",
      "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
      "            6.8382e-08,  1.1367e-07],\n",
      "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
      "            1.1723e-07,  1.4394e-07],\n",
      "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
      "            1.3333e-07,  1.5844e-07]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.1896e-02, -3.0206e-02,  1.9225e-02,  ...,  4.3665e-02,\n",
      "           -2.2114e-02, -4.2214e-02],\n",
      "          [-3.8061e-02,  6.0774e-03,  4.5797e-02,  ...,  9.6029e-02,\n",
      "            5.9254e-02,  2.9958e-02],\n",
      "          [-2.9672e-02,  2.7766e-03,  2.0457e-02,  ...,  5.9828e-02,\n",
      "            4.1422e-02,  2.3134e-02],\n",
      "          ...,\n",
      "          [ 1.1916e-02,  4.5701e-02,  4.4892e-02,  ...,  4.7419e-02,\n",
      "            2.2274e-02, -5.4993e-03],\n",
      "          [-3.2468e-02, -1.2210e-02,  2.2023e-02,  ...,  5.8061e-02,\n",
      "           -7.5033e-03, -5.9736e-02],\n",
      "          [-4.3314e-02, -2.8162e-02, -5.9126e-03,  ...,  8.8460e-02,\n",
      "            8.4406e-03, -5.0019e-02]],\n",
      "\n",
      "         [[-6.1292e-02, -1.4004e-02,  1.7229e-02,  ...,  1.8349e-02,\n",
      "           -3.2708e-02, -4.1060e-02],\n",
      "          [-3.1506e-02,  2.4460e-02,  4.5516e-02,  ...,  6.6806e-02,\n",
      "            4.6687e-02,  3.3248e-02],\n",
      "          [-3.2216e-02,  2.0718e-02,  2.3343e-02,  ...,  3.5265e-02,\n",
      "            3.6478e-02,  3.1291e-02],\n",
      "          ...,\n",
      "          [ 1.7739e-02,  6.1040e-02,  4.8247e-02,  ...,  3.7785e-02,\n",
      "            2.8894e-02,  1.3984e-02],\n",
      "          [-1.0890e-02,  2.2079e-02,  4.2737e-02,  ...,  6.0247e-02,\n",
      "            1.6197e-02, -1.2493e-02],\n",
      "          [-2.2284e-02,  1.3220e-02,  3.0897e-02,  ...,  1.0403e-01,\n",
      "            4.0119e-02, -5.3310e-03]],\n",
      "\n",
      "         [[-8.5322e-02, -4.2603e-02,  6.8145e-03,  ...,  3.0751e-02,\n",
      "           -3.4818e-02, -4.9945e-02],\n",
      "          [-2.9215e-02,  1.8165e-02,  5.1092e-02,  ...,  9.0200e-02,\n",
      "            5.3438e-02,  4.0169e-02],\n",
      "          [-3.9932e-02, -1.1100e-03,  9.6176e-03,  ...,  2.4114e-02,\n",
      "            2.6298e-02,  2.5489e-02],\n",
      "          ...,\n",
      "          [-3.1890e-03,  3.0454e-02,  1.6316e-02,  ...,  5.5054e-03,\n",
      "           -6.2689e-03, -8.4638e-03],\n",
      "          [-2.2995e-02, -2.8211e-03,  2.3203e-02,  ...,  3.5888e-02,\n",
      "           -1.4296e-02, -3.2419e-02],\n",
      "          [-9.8894e-03,  7.0542e-03,  1.0659e-02,  ...,  7.0495e-02,\n",
      "            1.2996e-02, -8.3417e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.8699e-03,  1.9911e-02,  3.4208e-02,  ...,  2.8694e-02,\n",
      "            1.2820e-02,  1.8142e-02],\n",
      "          [ 8.7942e-03, -3.2875e-02, -3.5713e-02,  ...,  7.2533e-02,\n",
      "            4.5889e-02,  5.2383e-02],\n",
      "          [-3.6122e-02, -1.1878e-01, -1.3767e-01,  ...,  3.3811e-02,\n",
      "            3.7806e-02,  2.6944e-02],\n",
      "          ...,\n",
      "          [ 1.7322e-02,  3.9589e-03, -8.2269e-03,  ...,  2.7543e-03,\n",
      "            1.8313e-02,  1.6057e-02],\n",
      "          [-9.5007e-04,  1.6428e-02,  1.7156e-02,  ...,  3.3672e-03,\n",
      "            2.2857e-02,  6.5783e-04],\n",
      "          [ 6.1727e-03,  2.7145e-02,  1.4340e-02,  ...,  7.5867e-03,\n",
      "            1.8770e-02,  1.5624e-02]],\n",
      "\n",
      "         [[-1.3423e-02, -5.0696e-04,  8.0959e-03,  ..., -6.0963e-03,\n",
      "            9.2341e-03,  1.5751e-02],\n",
      "          [-1.8343e-02, -6.7982e-02, -7.0685e-02,  ...,  2.9855e-02,\n",
      "            2.6264e-02,  2.3773e-02],\n",
      "          [-5.4359e-02, -1.4663e-01, -1.6211e-01,  ...,  1.1781e-02,\n",
      "            3.2477e-02,  1.1980e-02],\n",
      "          ...,\n",
      "          [ 8.3686e-04, -1.7564e-02, -1.9535e-02,  ..., -4.1382e-03,\n",
      "            2.4658e-02,  1.2893e-02],\n",
      "          [-6.3183e-04,  1.1788e-02,  2.4810e-02,  ...,  6.1105e-03,\n",
      "            3.9210e-02,  9.6696e-03],\n",
      "          [-7.1831e-03,  6.6918e-03,  5.2723e-03,  ..., -7.6077e-03,\n",
      "            2.7253e-02,  1.7735e-02]],\n",
      "\n",
      "         [[-2.3753e-04, -4.9343e-03,  2.2991e-03,  ..., -4.7958e-02,\n",
      "           -2.6154e-02, -2.3525e-02],\n",
      "          [-3.3053e-04, -5.1502e-02, -5.9977e-02,  ..., -1.7369e-02,\n",
      "           -2.3337e-02, -3.7312e-02],\n",
      "          [-2.2674e-02, -9.9412e-02, -1.1176e-01,  ..., -1.1725e-02,\n",
      "           -8.3744e-03, -4.0615e-02],\n",
      "          ...,\n",
      "          [ 1.1437e-02, -8.0313e-03, -1.4955e-03,  ..., -3.4133e-02,\n",
      "           -8.7267e-03, -2.3526e-02],\n",
      "          [ 2.9522e-03,  6.7770e-04,  1.9933e-02,  ..., -2.2002e-02,\n",
      "            1.4814e-02, -1.4487e-02],\n",
      "          [-1.9085e-02, -2.9430e-02, -2.3284e-02,  ..., -4.8587e-02,\n",
      "           -1.3049e-02, -2.4368e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6296e-02,  7.1996e-03,  1.9100e-02,  ...,  1.9602e-02,\n",
      "            1.4870e-02, -1.7298e-02],\n",
      "          [-1.1061e-02,  8.5665e-02,  1.2667e-01,  ...,  1.3744e-02,\n",
      "           -5.5036e-05, -3.0162e-02],\n",
      "          [ 1.1322e-01,  1.8634e-01,  5.0658e-02,  ..., -1.7333e-01,\n",
      "           -7.2041e-02, -6.2474e-02],\n",
      "          ...,\n",
      "          [-5.3062e-02, -2.5781e-01, -2.6747e-01,  ...,  2.6781e-01,\n",
      "            1.4344e-01,  5.5145e-02],\n",
      "          [-2.1009e-02, -2.9969e-02,  1.0245e-01,  ...,  2.0843e-01,\n",
      "           -4.1518e-03, -3.8118e-02],\n",
      "          [-2.2155e-02,  1.2380e-02,  8.4302e-02,  ..., -4.4992e-02,\n",
      "           -1.4687e-01, -9.0890e-02]],\n",
      "\n",
      "         [[-5.3969e-03,  3.2799e-02,  1.5486e-02,  ..., -7.7451e-03,\n",
      "            3.0229e-03,  1.1216e-03],\n",
      "          [ 6.1723e-02,  1.4899e-01,  1.4645e-01,  ..., -2.8897e-02,\n",
      "           -2.0227e-02, -9.1878e-03],\n",
      "          [ 1.6146e-01,  2.0886e-01, -2.5589e-02,  ..., -2.7278e-01,\n",
      "           -1.0735e-01, -6.2971e-02],\n",
      "          ...,\n",
      "          [-1.3723e-01, -4.0863e-01, -3.8551e-01,  ...,  4.0846e-01,\n",
      "            2.6202e-01,  1.3491e-01],\n",
      "          [-5.9388e-02, -6.1187e-02,  1.4197e-01,  ...,  3.5780e-01,\n",
      "            9.0893e-02, -1.7392e-03],\n",
      "          [ 7.8613e-03,  5.8403e-02,  1.5339e-01,  ...,  4.7045e-02,\n",
      "           -1.0095e-01, -9.7920e-02]],\n",
      "\n",
      "         [[-5.6799e-03,  1.3425e-02, -2.6461e-02,  ...,  4.4881e-03,\n",
      "            2.0666e-03,  1.3902e-02],\n",
      "          [ 6.5943e-03,  4.5181e-02,  6.0260e-02,  ...,  1.4368e-02,\n",
      "           -5.0725e-03,  4.0505e-03],\n",
      "          [ 5.5257e-02,  1.2397e-01,  4.3193e-02,  ..., -1.4486e-01,\n",
      "           -7.4489e-02, -5.7533e-02],\n",
      "          ...,\n",
      "          [-3.1513e-02, -1.6334e-01, -1.5795e-01,  ...,  2.2904e-01,\n",
      "            1.2017e-01,  7.1998e-02],\n",
      "          [-1.0456e-02, -1.1248e-03,  8.4582e-02,  ...,  1.5748e-01,\n",
      "            2.2142e-02, -1.0083e-02],\n",
      "          [-4.8639e-03, -5.0065e-03,  3.6341e-02,  ..., -2.4361e-02,\n",
      "           -7.1195e-02, -6.6788e-02]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "q = model_fa.conv1.weight\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010a49f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fa = nn.DataParallel(model_fa)\n",
    "model_fa.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ebe373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bp = resnet.resnet18(pretrained=True)\n",
    "model_bp.fc = nn.Linear(512, 10)\n",
    "model_bp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e70d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "loss_crossentropy = torch.nn.CrossEntropyLoss()\n",
    "optimizer_fa = torch.optim.RMSprop(model_fa.parameters(), lr=1e-4, weight_decay=0.)\n",
    "optimizer_bp = torch.optim.RMSprop(model_bp.parameters(), lr=1e-4, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-italy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd89aeb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-83523cae6918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model_fa.modules()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b068c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "facial-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_train = open('results' + 'conv_log2.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fundamental-strain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 100 loss_fa 1.00102698802948 loss_bp 0.3163323402404785\n",
      " time_fa 0.017718076705932617 time_bp 0.20459294319152832\n",
      "-0.1868748664855957\n",
      "epoch 0 step 200 loss_fa 0.8590705990791321 loss_bp 0.2614181339740753\n",
      " time_fa 0.017383813858032227 time_bp 0.2072312831878662\n",
      "-0.18984746932983398\n",
      "epoch 0 step 300 loss_fa 0.6312354803085327 loss_bp 0.26848942041397095\n",
      " time_fa 0.013391733169555664 time_bp 0.21135663986206055\n",
      "-0.19796490669250488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/projects/biotorch/.venv/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 0] Test results\n",
      "\tFA: Avg. loss: -2.2622, Accuracy: 7575/10000 (76%)\n",
      "\tBP: Avg. loss: -7.5389, Accuracy: 9340/10000 (93%)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f1a51c73a56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# flatten the inputs from square image to 1d vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#inputs = inputs.view(batch_size, -1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for idx_batch, (inputs, targets) in enumerate(train_loader):\n",
    "        # flatten the inputs from square image to 1d vector\n",
    "        #inputs = inputs.view(batch_size, -1)\n",
    "        # wrap them into varaibles\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # get outputs from the model\n",
    "        #print(\"inputs = \", inputs.size())\n",
    "        outputs_fa = model_fa(inputs)\n",
    "        outputs_bp = model_bp(inputs)\n",
    "        # print(outputs_fa.size())\n",
    "        # print(outputs_bp.size())\n",
    "        # calculate loss\n",
    "        outputs_fa = torch.squeeze(outputs_fa)\n",
    "        outputs_bp = torch.squeeze(outputs_bp)\n",
    "        # print(outputs_fa.size())\n",
    "        # print(outputs_bp.size())\n",
    "\n",
    "        # print(\"-\"*20)\n",
    "        #print(\"targets.size() = \", targets.size())\n",
    "        # input()\n",
    "        \n",
    "        loss_bp = loss_crossentropy(outputs_bp, targets)\n",
    "        loss_fa = loss_crossentropy(outputs_fa, targets)\n",
    "        # print(loss_bp, loss_fa)\n",
    "        \n",
    "        t_fa = time.time()\n",
    "        model_fa.zero_grad()\n",
    "        loss_fa.backward()\n",
    "        optimizer_fa.step()\n",
    "        t_avg_fa = time.time() - t_fa\n",
    "    \n",
    "        t_bp = time.time()\n",
    "        model_bp.zero_grad()\n",
    "        loss_bp.backward()\n",
    "        optimizer_bp.step()\n",
    "        t_avg_bp = time.time() - t_bp\n",
    "\n",
    "        if (idx_batch + 1) % 100 == 0:\n",
    "            train_log = 'epoch ' + str(epoch) + ' step ' + str(idx_batch + 1) + \\\n",
    "                        ' loss_fa ' + str(loss_fa.data.item()) + ' loss_bp ' + str(loss_bp.data.item())\n",
    "                         \n",
    "            times = ' time_fa '+ str(t_avg_fa) + ' time_bp ' + str(t_avg_bp)\n",
    "            time_dif = t_avg_fa - t_avg_bp\n",
    "            print(train_log)\n",
    "            print(times)\n",
    "            print(time_dif)\n",
    "            logger_train.write(train_log + '\\n')\n",
    "\n",
    "    # Test models\n",
    "    test_loss_fa, correct_fa = test(model_fa, test_loader, batch_size)    \n",
    "    test_loss_bp, correct_bp = test(model_bp, test_loader, batch_size)\n",
    "\n",
    "    print('\\n[Epoch {}] Test results'.format(epoch))\n",
    "    print('\\tFA: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(test_loss_fa,\n",
    "                                                                      correct_fa, len(test_loader.dataset), 100. * correct_fa / len(test_loader.dataset)))\n",
    "    print('\\tBP: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss_bp,\n",
    "                                                                        correct_bp, len(test_loader.dataset), 100. * correct_bp / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-republic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-camera",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d20153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e7451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biotorch",
   "language": "python",
   "name": "makrout"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
