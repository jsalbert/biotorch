{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241b7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from biotorch.initialization.functions import convert_module\n",
    "from biotorch.layers import Linear, Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6036da",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cba9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Classic LeNet Architecture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, activation='tanh'):\n",
    "        \"\"\"\n",
    "        :param in_features: dimension of input features (784 for MNIST)\n",
    "        :param num_layers: number of layers for feed-forward net\n",
    "        :param num_hidden_list: list of integers indicating hidden nodes of each layer\n",
    "        \"\"\"\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = torch.relu\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = torch.tanh\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = torch.sigmoid\n",
    "\n",
    "        # create layer operations\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        forward pass, which is same for conventional feed-forward net\n",
    "        :param inputs: inputs with shape [batch_size, in_features]\n",
    "        :return: logit outputs from the network\n",
    "        \"\"\"\n",
    "        inputs = self.activation(self.conv1(inputs))\n",
    "        inputs = self.pool(inputs)\n",
    "\n",
    "        inputs = self.activation(self.conv2(inputs))\n",
    "        inputs = self.pool(inputs)\n",
    "\n",
    "        inputs = inputs.view(inputs.size()[0], -1)\n",
    "\n",
    "        inputs = self.activation(self.fc1(inputs))\n",
    "        inputs = self.fc2(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34202f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetFA(nn.Module):\n",
    "    \"\"\"\n",
    "    Classic LeNet Architecture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, activation='tanh'):\n",
    "        \"\"\"\n",
    "        :param in_features: dimension of input features (784 for MNIST)\n",
    "        :param num_layers: number of layers for feed-forward net\n",
    "        :param num_hidden_list: list of integers indicating hidden nodes of each layer\n",
    "        \"\"\"\n",
    "        super(LeNetFA, self).__init__()\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = torch.relu\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = torch.tanh\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = torch.sigmoid\n",
    "\n",
    "        # create layer operations\n",
    "        self.conv1 = Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1, bias=False)\n",
    "        self.conv2 = Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = Linear(4 * 4 * 50, 500, bias=False)\n",
    "        self.fc2 = Linear(500, 10)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        forward pass, which is same for conventional feed-forward net\n",
    "        :param inputs: inputs with shape [batch_size, in_features]\n",
    "        :return: logit outputs from the network\n",
    "        \"\"\"\n",
    "        inputs = self.activation(self.conv1(inputs))\n",
    "        inputs = self.pool(inputs)\n",
    "\n",
    "        inputs = self.activation(self.conv2(inputs))\n",
    "        inputs = self.pool(inputs)\n",
    "\n",
    "        inputs = inputs.view(inputs.size()[0], -1)\n",
    "\n",
    "        inputs = self.activation(self.fc1(inputs))\n",
    "        inputs = self.fc2(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e04327",
   "metadata": {},
   "source": [
    "## Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ceceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, batch_size, device):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # Desactivate the autograd engine in test\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            #data = data.view(batch_size, -1)\n",
    "            inputs, targets = data.to(device), target.to(device)\n",
    "            predictions = model(inputs)\n",
    "            predictions = torch.squeeze(predictions)\n",
    "            test_loss += F.nll_loss(predictions, targets, size_average=False).item()\n",
    "            pred = predictions.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(targets.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec7f74d",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "841ed4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba340091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "# set up datasets\n",
    "print('==> Preparing data..')\n",
    "\n",
    "train_loader = DataLoader(datasets.MNIST('./data', train=True, download=True,\n",
    "                                             transform=transforms.Compose([\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                             ])),\n",
    "                              batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(datasets.MNIST('./data', train=False, download=True,\n",
    "                                            transform=transforms.Compose([\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                            ])),\n",
    "                             batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57898737",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12360e96",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806ca764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Back Propagation Model\n",
    "model_bp = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1319e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feedback Alignment model\n",
    "model_fa = LeNet()\n",
    "# model_fa = LeNetFA()\n",
    "# Uncomment for multiple GPUs\n",
    "# model_fa = nn.DataParallel(model_fa, device_ids=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059b233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the 2 <class 'torch.nn.modules.conv.Conv2d'> layers were converted successfully\n",
      "All the 2 <class 'torch.nn.modules.linear.Linear'> layers were converted successfully\n"
     ]
    }
   ],
   "source": [
    "convert_module(model_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1997309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can comment this to run on GPU\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23d0b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LeNet'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'biotorch.layers.conv.Conv2d'>\n",
      "<class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "<class 'biotorch.layers.linear.Linear'>\n",
      "<class 'biotorch.layers.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_fa.modules()):\n",
    "    print(type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f5f145b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95103b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fa.to(device)\n",
    "model_bp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3894a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizers\n",
    "loss_crossentropy = torch.nn.CrossEntropyLoss()\n",
    "optimizer_fa = torch.optim.RMSprop(model_fa.parameters(), lr=1e-4, weight_decay=0.)\n",
    "optimizer_bp = torch.optim.RMSprop(model_bp.parameters(), lr=1e-4, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ca8ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_train = open('results' + 'bp_vs_fa.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a318f5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 100 loss_fa 2.2755868434906006 loss_bp 0.79414963722229\n",
      " time_fa 0.005955219268798828 time_bp 0.003373861312866211\n",
      "0.002581357955932617\n",
      "epoch 0 step 200 loss_fa 2.055450201034546 loss_bp 0.36971384286880493\n",
      " time_fa 0.007066965103149414 time_bp 0.0032753944396972656\n",
      "0.0037915706634521484\n",
      "epoch 0 step 300 loss_fa 1.695908546447754 loss_bp 0.2870963513851166\n",
      " time_fa 0.00597381591796875 time_bp 0.0043735504150390625\n",
      "0.0016002655029296875\n",
      "epoch 0 step 400 loss_fa 1.3032976388931274 loss_bp 0.3816996216773987\n",
      " time_fa 0.006037712097167969 time_bp 0.003428936004638672\n",
      "0.002608776092529297\n",
      "epoch 0 step 500 loss_fa 0.8894603252410889 loss_bp 0.14889290928840637\n",
      " time_fa 0.0057566165924072266 time_bp 0.0032765865325927734\n",
      "0.002480030059814453\n",
      "epoch 0 step 600 loss_fa 0.7302398085594177 loss_bp 0.1579393446445465\n",
      " time_fa 0.006291627883911133 time_bp 0.010212421417236328\n",
      "-0.003920793533325195\n",
      "epoch 0 step 700 loss_fa 1.055591106414795 loss_bp 0.29359927773475647\n",
      " time_fa 0.005446672439575195 time_bp 0.0032193660736083984\n",
      "0.002227306365966797\n",
      "epoch 0 step 800 loss_fa 0.5344969630241394 loss_bp 0.16418275237083435\n",
      " time_fa 0.005843162536621094 time_bp 0.0035009384155273438\n",
      "0.00234222412109375\n",
      "epoch 0 step 900 loss_fa 0.6901041865348816 loss_bp 0.18297311663627625\n",
      " time_fa 0.005823373794555664 time_bp 0.0033864974975585938\n",
      "0.0024368762969970703\n",
      "epoch 0 step 1000 loss_fa 0.3674538731575012 loss_bp 0.07702426612377167\n",
      " time_fa 0.005980491638183594 time_bp 0.004380941390991211\n",
      "0.0015995502471923828\n",
      "epoch 0 step 1100 loss_fa 0.43077704310417175 loss_bp 0.10717849433422089\n",
      " time_fa 0.00568699836730957 time_bp 0.003568887710571289\n",
      "0.0021181106567382812\n",
      "epoch 0 step 1200 loss_fa 0.3393765985965729 loss_bp 0.1676684468984604\n",
      " time_fa 0.005832672119140625 time_bp 0.003362894058227539\n",
      "0.002469778060913086\n",
      "epoch 0 step 1300 loss_fa 0.5509087443351746 loss_bp 0.11731597036123276\n",
      " time_fa 0.005920886993408203 time_bp 0.004637718200683594\n",
      "0.0012831687927246094\n",
      "epoch 0 step 1400 loss_fa 0.72237229347229 loss_bp 0.15557140111923218\n",
      " time_fa 0.005655765533447266 time_bp 0.003233671188354492\n",
      "0.0024220943450927734\n",
      "epoch 0 step 1500 loss_fa 0.29659372568130493 loss_bp 0.15650403499603271\n",
      " time_fa 0.005615234375 time_bp 0.0032656192779541016\n",
      "0.0023496150970458984\n",
      "epoch 0 step 1600 loss_fa 0.2637883424758911 loss_bp 0.13293083012104034\n",
      " time_fa 0.0053708553314208984 time_bp 0.0033111572265625\n",
      "0.0020596981048583984\n",
      "epoch 0 step 1700 loss_fa 0.45933401584625244 loss_bp 0.11295048892498016\n",
      " time_fa 0.00585174560546875 time_bp 0.0035033226013183594\n",
      "0.0023484230041503906\n",
      "epoch 0 step 1800 loss_fa 0.44626936316490173 loss_bp 0.08889999985694885\n",
      " time_fa 0.006039142608642578 time_bp 0.004485607147216797\n",
      "0.0015535354614257812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albert/projects/biotorch/.venv/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 0] Test results\n",
      "\tFA: Avg. loss: -7.2105, Accuracy: 9186/10000 (92%)\n",
      "\tBP: Avg. loss: -8.7185, Accuracy: 9753/10000 (98%)\n",
      "\n",
      "epoch 1 step 100 loss_fa 0.27238550782203674 loss_bp 0.10038815438747406\n",
      " time_fa 0.007376194000244141 time_bp 0.0031604766845703125\n",
      "0.004215717315673828\n",
      "epoch 1 step 200 loss_fa 0.2137887179851532 loss_bp 0.04911723732948303\n",
      " time_fa 0.0055751800537109375 time_bp 0.003305673599243164\n",
      "0.0022695064544677734\n",
      "epoch 1 step 300 loss_fa 0.2731361985206604 loss_bp 0.043234437704086304\n",
      " time_fa 0.005491495132446289 time_bp 0.0033669471740722656\n",
      "0.0021245479583740234\n",
      "epoch 1 step 400 loss_fa 0.2416723519563675 loss_bp 0.08072543889284134\n",
      " time_fa 0.005636692047119141 time_bp 0.003507375717163086\n",
      "0.0021293163299560547\n",
      "epoch 1 step 500 loss_fa 0.21130669116973877 loss_bp 0.03591394051909447\n",
      " time_fa 0.0060503482818603516 time_bp 0.0033407211303710938\n",
      "0.002709627151489258\n",
      "epoch 1 step 600 loss_fa 0.4170858561992645 loss_bp 0.05042315274477005\n",
      " time_fa 0.005974292755126953 time_bp 0.0035905838012695312\n",
      "0.002383708953857422\n",
      "epoch 1 step 700 loss_fa 0.19407863914966583 loss_bp 0.048295117914676666\n",
      " time_fa 0.005769014358520508 time_bp 0.0034644603729248047\n",
      "0.002304553985595703\n",
      "epoch 1 step 800 loss_fa 0.15778762102127075 loss_bp 0.05847293883562088\n",
      " time_fa 0.005329608917236328 time_bp 0.003292083740234375\n",
      "0.002037525177001953\n",
      "epoch 1 step 900 loss_fa 0.42079970240592957 loss_bp 0.08708253502845764\n",
      " time_fa 0.0070552825927734375 time_bp 0.003273487091064453\n",
      "0.0037817955017089844\n",
      "epoch 1 step 1000 loss_fa 0.04729234799742699 loss_bp 0.00937039777636528\n",
      " time_fa 0.005578517913818359 time_bp 0.0033979415893554688\n",
      "0.0021805763244628906\n",
      "epoch 1 step 1100 loss_fa 0.2181885987520218 loss_bp 0.25716710090637207\n",
      " time_fa 0.00544285774230957 time_bp 0.0033659934997558594\n",
      "0.002076864242553711\n",
      "epoch 1 step 1200 loss_fa 0.21202562749385834 loss_bp 0.04229080304503441\n",
      " time_fa 0.005812168121337891 time_bp 0.0036361217498779297\n",
      "0.002176046371459961\n",
      "epoch 1 step 1300 loss_fa 0.1782779097557068 loss_bp 0.027032189071178436\n",
      " time_fa 0.005594015121459961 time_bp 0.003316164016723633\n",
      "0.002277851104736328\n",
      "epoch 1 step 1400 loss_fa 0.1797301024198532 loss_bp 0.029427094385027885\n",
      " time_fa 0.005840301513671875 time_bp 0.003528118133544922\n",
      "0.002312183380126953\n",
      "epoch 1 step 1500 loss_fa 0.12410421669483185 loss_bp 0.02914389967918396\n",
      " time_fa 0.005659341812133789 time_bp 0.004449605941772461\n",
      "0.0012097358703613281\n",
      "epoch 1 step 1600 loss_fa 0.07155361771583557 loss_bp 0.009034711867570877\n",
      " time_fa 0.0055179595947265625 time_bp 0.0032439231872558594\n",
      "0.002274036407470703\n",
      "epoch 1 step 1700 loss_fa 0.26612719893455505 loss_bp 0.05204248055815697\n",
      " time_fa 0.005468130111694336 time_bp 0.003251791000366211\n",
      "0.002216339111328125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e7035a9e9282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmodel_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moptimizer_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mt_avg_fa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_fa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/optim/rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             F.rmsprop(params_with_grad,\n\u001b[0m\u001b[1;32m    107\u001b[0m                       \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                       \u001b[0msquare_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36mrmsprop\u001b[0;34m(params, grads, square_avgs, grad_avgs, momentum_buffer_list, lr, alpha, eps, weight_decay, momentum, centered)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for idx_batch, (inputs, targets) in enumerate(train_loader):\n",
    "        # flatten the inputs from square image to 1d vector\n",
    "        #inputs = inputs.view(batch_size, -1)\n",
    "        # wrap them into varaibles\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # get outputs from the model\n",
    "        #print(\"inputs = \", inputs.size())\n",
    "        outputs_fa = model_fa(inputs)\n",
    "        outputs_bp = model_bp(inputs)\n",
    "        # print(outputs_fa.size())\n",
    "        # print(outputs_bp.size())\n",
    "        # calculate loss\n",
    "        outputs_fa = torch.squeeze(outputs_fa)\n",
    "        outputs_bp = torch.squeeze(outputs_bp)\n",
    "        # print(outputs_fa.size())\n",
    "        # print(outputs_bp.size())\n",
    "\n",
    "        # print(\"-\"*20)\n",
    "        #print(\"targets.size() = \", targets.size())\n",
    "        # input()\n",
    "        \n",
    "        loss_bp = loss_crossentropy(outputs_bp, targets)\n",
    "        loss_fa = loss_crossentropy(outputs_fa, targets)\n",
    "        # print(loss_bp, loss_fa)\n",
    "        \n",
    "        t_bp = time.time()\n",
    "        model_bp.zero_grad()\n",
    "        loss_bp.backward()\n",
    "        optimizer_bp.step()\n",
    "        t_avg_bp = time.time() - t_bp\n",
    "        \n",
    "        t_fa = time.time()\n",
    "        model_fa.zero_grad()\n",
    "        loss_fa.backward()\n",
    "        optimizer_fa.step()\n",
    "        t_avg_fa = time.time() - t_fa\n",
    "\n",
    "        if (idx_batch + 1) % 100 == 0:\n",
    "            train_log = 'epoch ' + str(epoch) + ' step ' + str(idx_batch + 1) + \\\n",
    "                        ' loss_fa ' + str(loss_fa.data.item()) + ' loss_bp ' + str(loss_bp.data.item())\n",
    "                         \n",
    "            times = ' time_fa '+ str(t_avg_fa) + ' time_bp ' + str(t_avg_bp)\n",
    "            time_dif = t_avg_fa - t_avg_bp\n",
    "            print(train_log)\n",
    "            print(times)\n",
    "            print(time_dif)\n",
    "            logger_train.write(train_log + '\\n')\n",
    "\n",
    "    # Test models\n",
    "    test_loss_fa, correct_fa = test(model_fa, test_loader, batch_size, device)    \n",
    "    test_loss_bp, correct_bp = test(model_bp, test_loader, batch_size, device)\n",
    "\n",
    "    print('\\n[Epoch {}] Test results'.format(epoch))\n",
    "    print('\\tFA: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(test_loss_fa,\n",
    "                                                                      correct_fa, len(test_loader.dataset), 100. * correct_fa / len(test_loader.dataset)))\n",
    "    print('\\tBP: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss_bp,\n",
    "                                                                        correct_bp, len(test_loader.dataset), 100. * correct_bp / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bccd003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a9feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa76c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biotorch",
   "language": "python",
   "name": "biotorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
