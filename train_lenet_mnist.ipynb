{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optical-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from biotorch.initialization.functions import add_fa_weight_matrices, override_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90da05",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5dd3050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Classic LeNet Architecture\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, activation='tanh'):\n",
    "        \"\"\"\n",
    "        :param in_features: dimension of input features (784 for MNIST)\n",
    "        :param num_layers: number of layers for feed-forward net\n",
    "        :param num_hidden_list: list of integers indicating hidden nodes of each layer\n",
    "        \"\"\"\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.activation = torch.relu\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = torch.tanh\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = torch.sigmoid\n",
    "\n",
    "        # create layer operations\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        forward pass, which is same for conventional feed-forward net\n",
    "        :param inputs: inputs with shape [batch_size, in_features]\n",
    "        :return: logit outputs from the network\n",
    "        \"\"\"\n",
    "        inputs = self.activation(self.conv1(inputs))\n",
    "        inputs = self.pool(inputs)\n",
    "\n",
    "        inputs = self.activation(self.conv2(inputs))\n",
    "        inputs = self.pool(inputs)\n",
    "\n",
    "        inputs = inputs.view(inputs.size()[0], -1)\n",
    "\n",
    "        inputs = self.activation(self.fc1(inputs))\n",
    "        inputs = self.fc2(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc1974",
   "metadata": {},
   "source": [
    "## Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "colored-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, batch_size):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # Desactivate the autograd engine in test\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            #data = data.view(batch_size, -1)\n",
    "            inputs, targets = Variable(data), Variable(target)\n",
    "            predictions = model(inputs)\n",
    "            predictions = torch.squeeze(predictions)\n",
    "            test_loss += F.nll_loss(predictions, targets, size_average=False).item()\n",
    "            pred = predictions.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(targets.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d904d54",
   "metadata": {},
   "source": [
    "## Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c64f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developmental-stanley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "# set up datasets\n",
    "print('==> Preparing data..')\n",
    "\n",
    "train_loader = DataLoader(datasets.MNIST('./data', train=True, download=True,\n",
    "                                             transform=transforms.Compose([\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                             ])),\n",
    "                              batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(datasets.MNIST('./data', train=False, download=True,\n",
    "                                            transform=transforms.Compose([\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                            ])),\n",
    "                             batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1085edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "standard-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Back Propagation Model\n",
    "model_bp = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b6a2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Feedback Alignment model\n",
    "model_fa = LeNet()\n",
    "model_fa.apply(add_fa_weight_matrices)\n",
    "model_fa.apply(override_backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "banned-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizers\n",
    "loss_crossentropy = torch.nn.CrossEntropyLoss()\n",
    "optimizer_fa = torch.optim.RMSprop(model_fa.parameters(), lr=1e-4, weight_decay=0.)\n",
    "optimizer_bp = torch.optim.RMSprop(model_bp.parameters(), lr=1e-4, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "facial-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_train = open('results' + 'bp_vs_fa.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fundamental-strain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 100 loss_fa 2.289576768875122 loss_bp 0.48975104093551636\n",
      " time_fa 0.004975795745849609 time_bp 0.0031325817108154297\n",
      "0.0018432140350341797\n",
      "epoch 0 step 200 loss_fa 2.3212621212005615 loss_bp 0.3316233158111572\n",
      " time_fa 0.00700831413269043 time_bp 0.0030548572540283203\n",
      "0.003953456878662109\n",
      "epoch 0 step 300 loss_fa 2.2434606552124023 loss_bp 0.20227667689323425\n",
      " time_fa 0.004949092864990234 time_bp 0.004687786102294922\n",
      "0.0002613067626953125\n",
      "epoch 0 step 400 loss_fa 2.230257272720337 loss_bp 0.30829137563705444\n",
      " time_fa 0.004934549331665039 time_bp 0.002972126007080078\n",
      "0.001962423324584961\n",
      "epoch 0 step 500 loss_fa 1.6380740404129028 loss_bp 0.2045004963874817\n",
      " time_fa 0.005754947662353516 time_bp 0.003685474395751953\n",
      "0.0020694732666015625\n",
      "epoch 0 step 600 loss_fa 1.3799012899398804 loss_bp 0.4044763743877411\n",
      " time_fa 0.0051610469818115234 time_bp 0.0031294822692871094\n",
      "0.002031564712524414\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8c491a6d1501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mt_fa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmodel_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mt_avg_fa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_fa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/biotorch/autograd/functions.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(context, grad_output)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mgrad_kernels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernels_fa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_input_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/biotorch/.venv/lib/python3.8/site-packages/torch/nn/grad.py\u001b[0m in \u001b[0;36mconv2d_weight\u001b[0;34m(input, weight_size, grad_output, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                     input.shape[2], input.shape[3])\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     grad_weight = torch.conv2d(input, grad_output, None, dilation, padding,\n\u001b[0m\u001b[1;32m    210\u001b[0m                                stride, in_channels * min_batch)\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for idx_batch, (inputs, targets) in enumerate(train_loader):\n",
    "        # flatten the inputs from square image to 1d vector\n",
    "        #inputs = inputs.view(batch_size, -1)\n",
    "        # wrap them into varaibles\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        # get outputs from the model\n",
    "        #print(\"inputs = \", inputs.size())\n",
    "        outputs_fa = model_fa(inputs)\n",
    "        outputs_bp = model_bp(inputs)\n",
    "        # print(outputs_fa.size())\n",
    "        # print(outputs_bp.size())\n",
    "        # calculate loss\n",
    "        outputs_fa = torch.squeeze(outputs_fa)\n",
    "        outputs_bp = torch.squeeze(outputs_bp)\n",
    "        # print(outputs_fa.size())\n",
    "        # print(outputs_bp.size())\n",
    "\n",
    "        # print(\"-\"*20)\n",
    "        #print(\"targets.size() = \", targets.size())\n",
    "        # input()\n",
    "        \n",
    "        loss_bp = loss_crossentropy(outputs_bp, targets)\n",
    "        loss_fa = loss_crossentropy(outputs_fa, targets)\n",
    "        # print(loss_bp, loss_fa)\n",
    "        \n",
    "        t_fa = time.time()\n",
    "        model_fa.zero_grad()\n",
    "        loss_fa.backward()\n",
    "        optimizer_fa.step()\n",
    "        t_avg_fa = time.time() - t_fa\n",
    "    \n",
    "        t_bp = time.time()\n",
    "        model_bp.zero_grad()\n",
    "        loss_bp.backward()\n",
    "        optimizer_bp.step()\n",
    "        t_avg_bp = time.time() - t_bp\n",
    "\n",
    "        if (idx_batch + 1) % 100 == 0:\n",
    "            train_log = 'epoch ' + str(epoch) + ' step ' + str(idx_batch + 1) + \\\n",
    "                        ' loss_fa ' + str(loss_fa.data.item()) + ' loss_bp ' + str(loss_bp.data.item())\n",
    "                         \n",
    "            times = ' time_fa '+ str(t_avg_fa) + ' time_bp ' + str(t_avg_bp)\n",
    "            time_dif = t_avg_fa - t_avg_bp\n",
    "            print(train_log)\n",
    "            print(times)\n",
    "            print(time_dif)\n",
    "            logger_train.write(train_log + '\\n')\n",
    "\n",
    "    # Test models\n",
    "    test_loss_fa, correct_fa = test(model_fa, test_loader, batch_size)    \n",
    "    test_loss_bp, correct_bp = test(model_bp, test_loader, batch_size)\n",
    "\n",
    "    print('\\n[Epoch {}] Test results'.format(epoch))\n",
    "    print('\\tFA: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(test_loss_fa,\n",
    "                                                                      correct_fa, len(test_loader.dataset), 100. * correct_fa / len(test_loader.dataset)))\n",
    "    print('\\tBP: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss_bp,\n",
    "                                                                        correct_bp, len(test_loader.dataset), 100. * correct_bp / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "threatened-republic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _VariableFunctionsClass.relu>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-camera",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biotorch",
   "language": "python",
   "name": "makrout"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
